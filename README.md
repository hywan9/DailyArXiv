# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-09-21

## Time Series
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use](http://arxiv.org/abs/2509.15153v1)** | 2025-09-18 | <details><summary>Show</summary><p>Multivariate time-series anomaly detection, which is critical for identifying unexpected events, has been explored in the field of machine learning for several decades. However, directly applying these methods to data from forceful tool use tasks is challenging because streaming sensor data in the real world tends to be inherently noisy, exhibits non-stationary behavior, and varies across different tasks and tools. To address these challenges, we propose a method, AnoF-Diff, based on the diffusion model to extract force-torque features from time-series data and use force-torque features to detect anomalies. We compare our method with other state-of-the-art methods in terms of F1-score and Area Under the Receiver Operating Characteristic curve (AUROC) on four forceful tool-use tasks, demonstrating that our method has better performance and is more robust to a noisy dataset. We also propose the method of parallel anomaly score evaluation based on one-step diffusion and demonstrate how our method can be used for online anomaly detection in several forceful tool use experiments.</p></details> |  |
| **[Super-Linear: A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting](http://arxiv.org/abs/2509.15105v1)** | 2025-09-18 | <details><summary>Show</summary><p>Time series forecasting (TSF) is critical in domains like energy, finance, healthcare, and logistics, requiring models that generalize across diverse datasets. Large pre-trained models such as Chronos and Time-MoE show strong zero-shot (ZS) performance but suffer from high computational costs. In this work, We introduce Super-Linear, a lightweight and scalable mixture-of-experts (MoE) model for general forecasting. It replaces deep architectures with simple frequency-specialized linear experts, trained on resampled data across multiple frequency regimes. A lightweight spectral gating mechanism dynamically selects relevant experts, enabling efficient, accurate forecasting. Despite its simplicity, Super-Linear matches state-of-the-art performance while offering superior efficiency, robustness to various sampling rates, and enhanced interpretability. The implementation of Super-Linear is available at \href{https://github.com/azencot-group/SuperLinear}{https://github.com/azencot-group/SuperLinear}</p></details> |  |
| **[Improving Internet Traffic Matrix Prediction via Time Series Clustering](http://arxiv.org/abs/2509.15072v1)** | 2025-09-18 | <details><summary>Show</summary><p>We present a novel framework that leverages time series clustering to improve internet traffic matrix (TM) prediction using deep learning (DL) models. Traffic flows within a TM often exhibit diverse temporal behaviors, which can hinder prediction accuracy when training a single model across all flows. To address this, we propose two clustering strategies, source clustering and histogram clustering, that group flows with similar temporal patterns prior to model training. Clustering creates more homogeneous data subsets, enabling models to capture underlying patterns more effectively and generalize better than global prediction approaches that fit a single model to the entire TM. Compared to existing TM prediction methods, our method reduces RMSE by up to 92\% for Abilene and 75\% for G\'EANT. In routing scenarios, our clustered predictions also reduce maximum link utilization (MLU) bias by 18\% and 21\%, respectively, demonstrating the practical benefits of clustering when TMs are used for network optimization.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICMLA 2025</p></details> |
| **[From Patterns to Predictions: A Shapelet-Based Framework for Directional Forecasting in Noisy Financial Markets](http://arxiv.org/abs/2509.15040v1)** | 2025-09-18 | <details><summary>Show</summary><p>Directional forecasting in financial markets requires both accuracy and interpretability. Before the advent of deep learning, interpretable approaches based on human-defined patterns were prevalent, but their structural vagueness and scale ambiguity hindered generalization. In contrast, deep learning models can effectively capture complex dynamics, yet often offer limited transparency. To bridge this gap, we propose a two-stage framework that integrates unsupervised pattern extracion with interpretable forecasting. (i) SIMPC segments and clusters multivariate time series, extracting recurrent patterns that are invariant to amplitude scaling and temporal distortion, even under varying window sizes. (ii) JISC-Net is a shapelet-based classifier that uses the initial part of extracted patterns as input and forecasts subsequent partial sequences for short-term directional movement. Experiments on Bitcoin and three S&P 500 equities demonstrate that our method ranks first or second in 11 out of 12 metric--dataset combinations, consistently outperforming baselines. Unlike conventional deep learning models that output buy-or-sell signals without interpretable justification, our approach enables transparent decision-making by revealing the underlying pattern structures that drive predictive outcomes.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 7 figures, accepted at ACM CIKM 2025 conference</p></details> |
| **[Beyond Marginals: Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection](http://arxiv.org/abs/2509.15033v1)** | 2025-09-18 | <details><summary>Show</summary><p>In this paper, we aim to improve multivariate anomaly detection (AD) by modeling the \textit{time-varying non-linear spatio-temporal correlations} found in multivariate time series data . In multivariate time series data, an anomaly may be indicated by the simultaneous deviation of interrelated time series from their expected collective behavior, even when no individual time series exhibits a clearly abnormal pattern on its own. In many existing approaches, time series variables are assumed to be (conditionally) independent, which oversimplifies real-world interactions. Our approach addresses this by modeling joint dependencies in the latent space and decoupling the modeling of \textit{marginal distributions, temporal dynamics, and inter-variable dependencies}. We use a transformer encoder to capture temporal patterns, and to model spatial (inter-variable) dependencies, we fit a multi-variate likelihood and a copula. The temporal and the spatial components are trained jointly in a latent space using a self-supervised contrastive learning objective to learn meaningful feature representations to separate normal and anomaly samples.</p></details> |  |
| **[Warp Quantification Analysis: A Framework For Path-based Signal Alignment Metrics](http://arxiv.org/abs/2509.14994v1)** | 2025-09-18 | <details><summary>Show</summary><p>Dynamic time warping (DTW) is widely used to align time series evolving on mismatched timescales, yet most applications reduce alignment to a scalar distance. We introduce warp quantification analysis (WQA), a framework that derives interpretable geometric and structural descriptors from DTW paths. Controlled simulations showed that each metric selectively tracked its intended driver with minimal crosstalk. Applied to large-scale fMRI, WQA revealed distinct network signatures and complementary associations with schizophrenia negative symptom severity, capturing clinically meaningful variability beyond DTW distance. WQA transforms DTW from a single-score method into a family of alignment descriptors, offering a principled and generalizable extension for richer characterization of temporal coupling across domains where nonlinear normalization is essential.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 3 figures, conference</p></details> |
| **[DAG: A Dual Causal Network for Time Series Forecasting with Exogenous Variables](http://arxiv.org/abs/2509.14933v1)** | 2025-09-18 | <details><summary>Show</summary><p>Time series forecasting is crucial in various fields such as economics, traffic, and AIOps. However, in real-world applications, focusing solely on the endogenous variables (i.e., target variables), is often insufficient to ensure accurate predictions. Considering exogenous variables (i.e., covariates) provides additional predictive information, thereby improving forecasting accuracy. However, existing methods for time series forecasting with exogenous variables (TSF-X) have the following shortcomings: 1) they do not leverage future exogenous variables, 2) they fail to account for the causal relationships between endogenous and exogenous variables. As a result, their performance is suboptimal. In this study, to better leverage exogenous variables, especially future exogenous variable, we propose a general framework DAG, which utilizes dual causal network along both the temporal and channel dimensions for time series forecasting with exogenous variables. Specifically, we first introduce the Temporal Causal Module, which includes a causal discovery module to capture how historical exogenous variables affect future exogenous variables. Following this, we construct a causal injection module that incorporates the discovered causal relationships into the process of forecasting future endogenous variables based on historical endogenous variables. Next, we propose the Channel Causal Module, which follows a similar design principle. It features a causal discovery module models how historical exogenous variables influence historical endogenous variables, and a causal injection module incorporates the discovered relationships to enhance the prediction of future endogenous variables based on future exogenous variables.</p></details> |  |
| **[DPANet: Dual Pyramid Attention Network for Multivariate Time Series Forecasting](http://arxiv.org/abs/2509.14868v1)** | 2025-09-18 | <details><summary>Show</summary><p>We conducted rigorous ablation studies to validate DPANet's key components (Table \ref{tab:ablation-study}). The full model consistently outperforms all variants. To test our dual-domain hypothesis, we designed two specialized versions: a Temporal-Only model (fusing two identical temporal pyramids) and a Frequency-Only model (fusing two spectral pyramids). Both variants underperformed significantly, confirming that the fusion of heterogeneous temporal and frequency information is critical. Furthermore, replacing the cross-attention mechanism with a simpler method (w/o Cross-Fusion) caused the most severe performance degradation. This result underscores that our interactive fusion block is the most essential component.</p></details> |  |
| **[Diffusion-Based Scenario Tree Generation for Multivariate Time Series Prediction and Multistage Stochastic Optimization](http://arxiv.org/abs/2509.14832v1)** | 2025-09-18 | <details><summary>Show</summary><p>Stochastic forecasting is critical for efficient decision-making in uncertain systems, such as energy markets and finance, where estimating the full distribution of future scenarios is essential. We propose Diffusion Scenario Tree (DST), a general framework for constructing scenario trees for multivariate prediction tasks using diffusion-based probabilistic forecasting models. DST recursively samples future trajectories and organizes them into a tree via clustering, ensuring non-anticipativity (decisions depending only on observed history) at each stage. We evaluate the framework on the optimization task of energy arbitrage in New York State's day-ahead electricity market. Experimental results show that our approach consistently outperforms the same optimization algorithms that use scenario trees from more conventional models and Model-Free Reinforcement Learning baselines. Furthermore, using DST for stochastic optimization yields more efficient decision policies, achieving higher performance by better handling uncertainty than deterministic and stochastic MPC variants using the same diffusion-based forecaster.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 2 figures, 2 tables, and 1 algorithm. This version is submitted to the 51st IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026), to be held in Barcelona, Spain, on May 4-8, 2026</p></details> |
| **[Forecasting in small open emerging economies Evidence from Thailand](http://arxiv.org/abs/2509.14805v1)** | 2025-09-18 | <details><summary>Show</summary><p>Forecasting inflation in small open economies is difficult because limited time series and strong external exposures create an imbalance between few observations and many potential predictors. We study this challenge using Thailand as a representative case, combining more than 450 domestic and international indicators. We evaluate modern Bayesian shrinkage and factor models, including Horseshoe regressions, factor-augmented autoregressions, factor-augmented VARs, dynamic factor models, and Bayesian additive regression trees. Our results show that factor models dominate at short horizons, when global shocks and exchange rate movements drive inflation, while shrinkage-based regressions perform best at longer horizons. These models not only improve point and density forecasts but also enhance tail-risk performance at the one-year horizon. Shrinkage diagnostics, on the other hand, additionally reveal that Google Trends variables, especially those related to food essential goods and housing costs, progressively rotate into predictive importance as the horizon lengthens. This underscores their role as forward-looking indicators of household inflation expectations in small open economies.</p></details> |  |
| **[DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework](http://arxiv.org/abs/2507.21830v4)** | 2025-09-18 | <details><summary>Show</summary><p>Multivariate Time Series Forecasting plays a key role in many applications. Recent works have explored using Large Language Models for MTSF to take advantage of their reasoning abilities. However, many methods treat LLMs as end-to-end forecasters, which often leads to a loss of numerical precision and forces LLMs to handle patterns beyond their intended design. Alternatively, methods that attempt to align textual and time series modalities within latent space frequently encounter alignment difficulty. In this paper, we propose to treat LLMs not as standalone forecasters, but as semantic guidance modules within a dual-stream framework. We propose DualSG, a dual-stream framework that provides explicit semantic guidance, where LLMs act as Semantic Guides to refine rather than replace traditional predictions. As part of DualSG, we introduce Time Series Caption, an explicit prompt format that summarizes trend patterns in natural language and provides interpretable context for LLMs, rather than relying on implicit alignment between text and time series in the latent space. We also design a caption-guided fusion module that explicitly models inter-variable relationships while reducing noise and computation. Experiments on real-world datasets from diverse domains show that DualSG consistently outperforms 15 state-of-the-art baselines, demonstrating the value of explicitly combining numerical forecasting with semantic guidance.</p></details> | <details><summary>This ...</summary><p>This paper has been accepted by ACM Multimedia 2025 (ACM MM 2025)</p></details> |
| **[DeCoP: Enhancing Self-Supervised Time Series Representation with Dependency Controlled Pre-training](http://arxiv.org/abs/2509.14642v1)** | 2025-09-18 | <details><summary>Show</summary><p>Modeling dynamic temporal dependencies is a critical challenge in time series pre-training, which evolve due to distribution shifts and multi-scale patterns. This temporal variability severely impairs the generalization of pre-trained models to downstream tasks. Existing frameworks fail to capture the complex interactions of short- and long-term dependencies, making them susceptible to spurious correlations that degrade generalization. To address these limitations, we propose DeCoP, a Dependency Controlled Pre-training framework that explicitly models dynamic, multi-scale dependencies by simulating evolving inter-patch dependencies. At the input level, DeCoP introduces Instance-wise Patch Normalization (IPN) to mitigate distributional shifts while preserving the unique characteristics of each patch, creating a robust foundation for representation learning. At the latent level, a hierarchical Dependency Controlled Learning (DCL) strategy explicitly models inter-patch dependencies across multiple temporal scales, with an Instance-level Contrastive Module (ICM) enhances global generalization by learning instance-discriminative representations from time-invariant positive pairs. DeCoP achieves state-of-the-art results on ten datasets with lower computing resources, improving MSE by 3% on ETTh1 over PatchTST using only 37% of the FLOPs.</p></details> |  |
| **[DyWPE: Signal-Aware Dynamic Wavelet Positional Encoding for Time Series Transformers](http://arxiv.org/abs/2509.14640v1)** | 2025-09-18 | <details><summary>Show</summary><p>Existing positional encoding methods in transformers are fundamentally signal-agnostic, deriving positional information solely from sequence indices while ignoring the underlying signal characteristics. This limitation is particularly problematic for time series analysis, where signals exhibit complex, non-stationary dynamics across multiple temporal scales. We introduce Dynamic Wavelet Positional Encoding (DyWPE), a novel signal-aware framework that generates positional embeddings directly from input time series using the Discrete Wavelet Transform (DWT). Comprehensive experiments in ten diverse time series datasets demonstrate that DyWPE consistently outperforms eight existing state-of-the-art positional encoding methods, achieving average relative improvements of 9.1\% compared to baseline sinusoidal absolute position encoding in biomedical signals, while maintaining competitive computational efficiency.</p></details> |  |
| **[AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting](http://arxiv.org/abs/2509.02967v2)** | 2025-09-18 | <details><summary>Show</summary><p>Traditional neural networks struggle to capture the spectral structure of complex signals. Fourier neural networks (FNNs) attempt to address this by embedding Fourier series components, yet many real-world signals are almost-periodic with non-commensurate frequencies, posing additional challenges. Building on prior work showing that ARIMA outperforms large language models (LLMs) for forecasting, we extend the comparison to neural predictors and find ARIMA still superior. We therefore propose the Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network (AR-KAN), which integrates a pre-trained AR module for temporal memory with a KAN for nonlinear representation. The AR module preserves essential temporal features while reducing redundancy. Experiments demonstrate that AR-KAN matches ARIMA on almost-periodic functions and achieves the best results on $72\%$ of Rdatasets series, with a clear advantage on data with periodic structure. These results highlight AR-KAN as a robust and effective framework for time series forecasting.</p></details> |  |
| **[Identification and Estimation of Multi-order Tensor Factor Models](http://arxiv.org/abs/2508.13418v2)** | 2025-09-18 | <details><summary>Show</summary><p>We propose a novel framework in high-dimensional factor models to simultaneously analyse multiple tensor time series, each with potentially different tensor orders and dimensionality. The connection between different tensor time series is through their global factors that are correlated to each other. A salient feature of our model is that when all tensor time series have the same order, it can be regarded as an extension of multilevel factor models from vectors to general tensors. Under very mild conditions, we separate the global and local components in the proposed model. Parameter estimation is thoroughly discussed, including a consistent factor number estimator. With strong correlation between global factors and noise allowed, we derive the rates of convergence of our estimators, which can be more superior than those of existing methods for multilevel factor models. We also develop estimators that are more computationally efficient, with rates of convergence spelt out. Extensive experiments are performed under various settings, corroborating with the pronounced theoretical results. As a real application example, we analyse a set of taxi data to study the traffic flow between Times Squares and its neighbouring areas.</p></details> | 45 pages, 3 figures |
| **[Nonlinear Causality in Time Series Networks: With Application to Motor Imagery vs Execution](http://arxiv.org/abs/2409.10374v3)** | 2025-09-18 | <details><summary>Show</summary><p>Causal interactions in time series networks can be dynamic and nonlinear, making it difficult to identify them using conventional linear causality estimations. We propose a novel approach, called Threshold Autoregressive Modeling for Causality (TAR4C), a causality detection approach built on threshold autoregressive (TAR) models, where a potential driver (cause variable) acts both as a predictor and as a trigger (switching threshold) that governs which autoregressive process the target (effect variable) follows. Threshold nonlinearity is conceptualized here to determine causality. The flow of the target is forced to transition between regimes with distinct dynamics when the driver exceeds a data-driven threshold in the past. We propose a two-stage inference procedure: Stage 1 tests for threshold connectivity (TC); Stage 2, conditional on a detected threshold effect, estimates threshold Granger causality (TGC). TAR4C is applied to a multichannel EEG dataset collected from a motor imagery and execution experiment. Delay-dependent directional interactions are observed among channels across different sites of the EEG map. The real-world application demonstrates the usefulness of the proposed approach for determining nonlinear causal connectivity in complex time-series networks, such as brain circuitry. The proposed model-based methodology extends to other complex networks of time series.</p></details> |  |
| **[Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](http://arxiv.org/abs/2509.14181v1)** | 2025-09-17 | <details><summary>Show</summary><p>Representation learning techniques like contrastive learning have long been explored in time series forecasting, mirroring their success in computer vision and natural language processing. Yet recent state-of-the-art (SOTA) forecasters seldom adopt these representation approaches because they have shown little performance advantage. We challenge this view and demonstrate that explicit representation alignment can supply critical information that bridges the distributional gap between input histories and future targets. To this end, we introduce TimeAlign, a lightweight, plug-and-play framework that learns auxiliary features via a simple reconstruction task and feeds them back to any base forecaster. Extensive experiments across eight benchmarks verify its superior performance. Further studies indicate that the gains arises primarily from correcting frequency mismatches between historical inputs and future outputs. We also provide a theoretical justification for the effectiveness of TimeAlign in increasing the mutual information between learned representations and predicted targets. As it is architecture-agnostic and incurs negligible overhead, TimeAlign can serve as a general alignment module for modern deep learning time-series forecasting systems. The code is available at https://github.com/TROUBADOUR000/TimeAlign.</p></details> |  |
| **[Canonical correlation analysis of stochastic trends via functional approximation](http://arxiv.org/abs/2411.19572v2)** | 2025-09-17 | <details><summary>Show</summary><p>This paper proposes a novel approach for semiparametric inference on the number $s$ of common trends and their loading matrix $\psi$ in $I(1)/I(0)$ systems. It combines functional approximation of limits of random walks and canonical correlations analysis, performed between the $p$ observed time series of length $T$ and the first $K$ discretized elements of an $L^2$ basis. Tests and selection criteria on $s$, and estimators and tests on $\psi$ are proposed; their properties are discussed as $T$ and $K$ diverge sequentially for fixed $p$ and $s$. It is found that tests on $s$ are asymptotically pivotal, selection criteria of $s$ are consistent, estimators of $\psi$ are $T$-consistent, mixed-Gaussian and efficient, so that Wald tests on $\psi$ are asymptotically Normal or $\chi^2$. The paper also discusses asymptotically pivotal misspecification tests for checking model assumptions. The approach can be coherently applied to subsets or aggregations of variables in a given panel. Monte Carlo simulations show that these tools have reasonable performance for $T\geq 10 p$ and $p\leq 300$. An empirical analysis of 20 exchange rates illustrates the methods.</p></details> |  |
| **[LLM-ABBA: Understanding time series via symbolic approximation](http://arxiv.org/abs/2411.18506v4)** | 2025-09-17 | <details><summary>Show</summary><p>The success of large language models (LLMs) for time series has been demonstrated in previous work. Utilizing a symbolic time series representation, one can efficiently bridge the gap between LLMs and time series. However, the remaining challenge is to exploit the semantic information hidden in time series by using symbols or existing tokens of LLMs, while aligning the embedding space of LLMs according to the hidden information of time series. The symbolic time series approximation (STSA) method called adaptive Brownian bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in preserving salient time series features by modeling time series patterns in terms of amplitude and period while using existing tokens of LLMs. In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA into large language models for various downstream time series tasks. By symbolizing time series, LLM-ABBA compares favorably to the recent state-of-the-art (SOTA) in UCR and three medical time series classification tasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to \kc{avoid obvious drifting} during prediction tasks by significantly mitigating the effects of cumulative error arising from misused symbols during the transition from symbols to numerical values. In time series regression tasks, LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER) benchmarks. LLM-ABBA also shows competitive prediction capability compared to recent SOTA time series prediction results. We believe this framework can also seamlessly extend to other time series tasks.</p></details> |  |
| **[CoVariance Filters and Neural Networks over Hilbert Spaces](http://arxiv.org/abs/2509.13178v2)** | 2025-09-17 | <details><summary>Show</summary><p>CoVariance Neural Networks (VNNs) perform graph convolutions on the empirical covariance matrix of signals defined over finite-dimensional Hilbert spaces, motivated by robustness and transferability properties. Yet, little is known about how these arguments extend to infinite-dimensional Hilbert spaces. In this work, we take a first step by introducing a novel convolutional learning framework for signals defined over infinite-dimensional Hilbert spaces, centered on the (empirical) covariance operator. We constructively define Hilbert coVariance Filters (HVFs) and design Hilbert coVariance Networks (HVNs) as stacks of HVF filterbanks with nonlinear activations. We propose a principled discretization procedure, and we prove that empirical HVFs can recover the Functional PCA (FPCA) of the filtered signals. We then describe the versatility of our framework with examples ranging from multivariate real-valued functions to reproducing kernel Hilbert spaces. Finally, we validate HVNs on both synthetic and real-world time-series classification tasks, showing robust performance compared to MLP and FPCA-based classifiers.</p></details> | 6 pages, 3 figures |
| **[Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](http://arxiv.org/abs/2509.14000v1)** | 2025-09-17 | <details><summary>Show</summary><p>Global Navigation Satellite Systems (GNSS) are increasingly disrupted by intentional jamming, degrading availability precisely when positioning and timing must remain operational. We address this by reframing jamming mitigation as dynamic graph regression and introducing a receiver-centric deep temporal graph network that predicts, and thus corrects, the receivers horizontal deviation in real time. At each 1 Hz epoch, the satellite receiver environment is represented as a heterogeneous star graph (receiver center, tracked satellites as leaves) with time varying attributes (e.g., SNR, azimuth, elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM (HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a short history to output the 2D deviation vector applied for on the fly correction. We evaluate on datasets from two distinct receivers under three jammer profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each exercised at six power levels between -45 and -70 dBm, with 50 repetitions per scenario (prejam/jam/recovery). Against strong multivariate time series baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm (GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and 4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10), outperforming Seq2Point, MLP, and CNN. A split study shows superior data efficiency: with only 10\% training data our approach remains well ahead of baselines (20 cm vs. 36-42 cm).</p></details> | 20 pages, 4 figures |
| **[Day-Ahead Transmission Grid Topology Optimization Considering Renewable Energy Sources' Uncertainty](http://arxiv.org/abs/2509.13994v1)** | 2025-09-17 | <details><summary>Show</summary><p>The increasing renewable penetration introduces significant uncertainty in power system operations. At the same time, the existing transmission grid is often already congested, and urgently needed reinforcements are frequently delayed due to several constraints. To address these challenges, adjusting the grid topology based on congestion patterns is considered a non-costly remedy to guarantee efficient power transmission. Based on this idea, this paper proposes a grid topology optimization model combining optimal transmission switching and busbar splitting for AC and hybrid AC/DC grids. The methodology incorporates RES forecast uncertainty through a scenario-based stochastic optimization approach, using real offshore wind data and K-means clustering to generate representative forecast error scenarios. The proposed model includes several formulations to be compared with a plain optimal power flow (OPF) model: hourly optimizing the topology, one topology for 24 hours, or a limited number of switching actions over a day. The grid topology optimization model is formulated as a Mixed-Integer Quadratic Convex Problem, optimized based on the day-ahead (D-1) RES forecast and validated for AC-feasibility via an AC-OPF formulation. Based on the generation setpoints of the feasibility check, a redispatch simulation based on the measured (D) RES realization is then computed. The methodology is tested on an AC 30-bus test case and a hybrid AC/DC 50-bus test case, for a 24-hours (30-bus) and a 14-days (both test cases) time series. The results highlight the economic benefits brought by grid topology optimization for congested test cases with high penetration of RES. In addition, the results demonstrate that accounting for RES uncertainty with at least 6 to 8 scenarios leads to lower or comparable total costs to deterministic day-ahead forecasts, even when limiting the frequency of topological actions.</p></details> |  |
| **[Ensembled Direct Multi Step forecasting methodology with comparison on macroeconomic and financial data](http://arxiv.org/abs/2509.13945v1)** | 2025-09-17 | <details><summary>Show</summary><p>Accurate forecasts of macroeconomic and financial data, such as GDP, CPI, unemployment rates, and stock indices, are crucial for the success of countries, businesses, and investors, resulting in a constant demand for reliable forecasting models. This research introduces a novel methodology for time series forecasting that combines Ensemble technique with a Direct Multi-Step (DMS) forecasting procedure. This Ensembled Direct Multi-Step (EDMS) approach not only leverages the strengths of both techniques but also capitalizes on their synergy. The ensemble models were selected based on performance, complexity, and computational resource requirements, encompassing a full spectrum of model complexities, from simple Linear and Polynomial Regression to medium-complexity ETS and complex LSTM models. Ensembling is carried out using weights derived from each model's performance. The DMS procedure limits retraining to one- and five-year forecasts for economic data and one- and five-month forecasts for financial data. The standard Iterative Multi-Step (IMS) procedure is employed for other horizons, effectively reducing computational demands while maintaining satisfactory results. The proposed methodology is benchmarked against the Ensemble technique conventionally applied to IMS-generated forecasts, utilizing several publicly available macroeconomic datasets, including GDP, CPI, and employment figures across selected countries, and common financial indices data. Results demonstrate a significant performance improvement with the EDMS methodology, averaging a 33.32% enhancement across the analysed datasets, and sometimes reaching improvement above 60%.</p></details> | 40 pages, 7 figures |
| **[TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](http://arxiv.org/abs/2509.13906v1)** | 2025-09-17 | <details><summary>Show</summary><p>Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art performance in univariate forecasting on new time series simply by conditioned on a brief history of past values. Their success demonstrates that large-scale pretraining across diverse domains can acquire the inductive bias to generalize from temporal patterns in a brief history. However, most TSFMs are unable to leverage covariates -- future-available exogenous variables critical for accurate forecasting in many applications -- due to their domain-specific nature and the lack of associated inductive bias. We propose TFMAdapter, a lightweight, instance-level adapter that augments TSFMs with covariate information without fine-tuning. Instead of retraining, TFMAdapter operates on the limited history provided during a single model call, learning a non-parametric cascade that combines covariates with univariate TSFM forecasts. However, such learning would require univariate forecasts at all steps in the history, requiring too many calls to the TSFM. To enable training on the full historical context while limiting TSFM invocations, TFMAdapter uses a two-stage method: (1) generating pseudo-forecasts with a simple regression model, and (2) training a Gaussian Process regressor to refine predictions using both pseudo- and TSFM forecasts alongside covariates. Extensive experiments on real-world datasets demonstrate that TFMAdapter consistently outperforms both foundation models and supervised baselines, achieving a 24-27\% improvement over base foundation models with minimal data and computational overhead. Our results highlight the potential of lightweight adapters to bridge the gap between generic foundation models and domain-specific forecasting needs.</p></details> | <details><summary>Accep...</summary><p>Accepted at CIKM 2025</p></details> |
| **[Prediction and Causality of functional MRI and synthetic signal using a Zero-Shot Time-Series Foundation Model](http://arxiv.org/abs/2509.12497v2)** | 2025-09-17 | <details><summary>Show</summary><p>Time-series forecasting and causal discovery are central in neuroscience, as predicting brain activity and identifying causal relationships between neural populations and circuits can shed light on the mechanisms underlying cognition and disease. With the rise of foundation models, an open question is how they compare to traditional methods for brain signal forecasting and causality analysis, and whether they can be applied in a zero-shot setting. In this work, we evaluate a foundation model against classical methods for inferring directional interactions from spontaneous brain activity measured with functional magnetic resonance imaging (fMRI) in humans. Traditional approaches often rely on Wiener-Granger causality. We tested the forecasting ability of the foundation model in both zero-shot and fine-tuned settings, and assessed causality by comparing Granger-like estimates from the model with standard Granger causality. We validated the approach using synthetic time series generated from ground-truth causal models, including logistic map coupling and Ornstein-Uhlenbeck processes. The foundation model achieved competitive zero-shot forecasting fMRI time series (mean absolute percentage error of 0.55 in controls and 0.27 in patients). Although standard Granger causality did not show clear quantitative differences between models, the foundation model provided a more precise detection of causal interactions. Overall, these findings suggest that foundation models offer versatility, strong zero-shot performance, and potential utility for forecasting and causal discovery in time-series data.</p></details> |  |
| **[Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models](http://arxiv.org/abs/2509.13839v1)** | 2025-09-17 | <details><summary>Show</summary><p>In this work, we address the problem of predicting the future success of open-vocabulary object manipulation tasks. Conventional approaches typically determine success or failure after the action has been carried out. However, they make it difficult to prevent potential hazards and rely on failures to trigger replanning, thereby reducing the efficiency of object manipulation sequences. To overcome these challenges, we propose a model, which predicts the alignment between a pre-manipulation egocentric image with the planned trajectory and a given natural language instruction. We introduce a Multi-Level Trajectory Fusion module, which employs a state-of-the-art deep state-space model and a transformer encoder in parallel to capture multi-level time-series self-correlation within the end effector trajectory. Our experimental results indicate that the proposed method outperformed existing methods, including foundation models.</p></details> | <details><summary>Publi...</summary><p>Published in Advanced Robotics</p></details> |
| **[Empowering Time Series Analysis with Foundation Models: A Comprehensive Survey](http://arxiv.org/abs/2405.02358v4)** | 2025-09-17 | <details><summary>Show</summary><p>Time series data are ubiquitous across diverse real-world applications, making time series analysis critically important. Traditional approaches are largely task-specific, offering limited functionality and poor transferability. In recent years, foundation models have revolutionized NLP and CV with their remarkable cross-task transferability, zero-/few-shot learning capabilities, and multimodal integration capacity. This success has motivated increasing efforts to explore foundation models for addressing time series modeling challenges. Although some tutorials and surveys were published in the early stages of this field, the rapid pace of recent developments necessitates a more comprehensive and in-depth synthesis to cover the latest advances. Our survey aims to fill this gap by introducing a modality-aware, challenge-oriented perspective, which reveals how foundation models pre-trained on different modalities face distinct hurdles when adapted to time series tasks. Building on this perspective, we propose a taxonomy of existing works organized by pre-training modality (time series, language, and vision), analyze modality-specific challenges and categorize corresponding solutions, discussing their advantages and limitations. Beyond this, we review real-world applications to illustrate domain-specific advancements, provide open-source codes, and conclude with potential future research directions in this rapidly evolving field.</p></details> | <details><summary>10 fi...</summary><p>10 figures, 5 tables, 20 pages</p></details> |
| **[Data-Efficient Sleep Staging with Synthetic Time Series Pretraining](http://arxiv.org/abs/2403.08592v2)** | 2025-09-17 | <details><summary>Show</summary><p>Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed "frequency pretraining" to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.</p></details> | <details><summary>15 pa...</summary><p>15 pages, 4 figures, 1 table</p></details> |
| **[Continuous Temporal Learning of Probability Distributions via Neural ODEs with Applications in Continuous Glucose Monitoring Data](http://arxiv.org/abs/2505.08698v3)** | 2025-09-17 | <details><summary>Show</summary><p>Modeling the dynamics of probability distributions from time-dependent data samples is a fundamental problem in many fields, including digital health. The goal is to analyze how the distribution of a biomarker, such as glucose, changes over time and how these changes may reflect the progression of chronic diseases such as diabetes. We introduce a probabilistic model based on a Gaussian mixture that captures the evolution of a continuous-time stochastic process. Our approach combines a nonparametric estimate of the distribution, obtained with Maximum Mean Discrepancy (MMD), and a Neural Ordinary Differential Equation (Neural ODE) that governs the temporal evolution of the mixture weights. The model is highly interpretable, detects subtle distribution shifts, and remains computationally efficient. We illustrate the broad utility of our approach in a 26-week clinical trial that treats all continuous glucose monitoring (CGM) time series as the primary outcome. This method enables rigorous longitudinal comparisons between the treatment and control arms and yields characterizations that conventional summary-based clinical trials analytical methods typically do not capture.</p></details> |  |
| **[Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](http://arxiv.org/abs/2509.13696v1)** | 2025-09-17 | <details><summary>Show</summary><p>Large language models (LLMs) excel at text generation, but their ability to handle clinical classification tasks involving structured data, such as time series, remains underexplored. In this work, we adapt instruction-tuned LLMs using DSPy-based prompt optimization to process clinical notes and structured EHR inputs jointly. Our results show that this approach achieves performance on par with specialized multimodal systems while requiring less complexity and offering greater adaptability across tasks.</p></details> | <details><summary>Prese...</summary><p>Presented and published at BioCreative IX</p></details> |
| **[A Stable Measure for Conditional Periodicity of Time Series using Persistent Homology](http://arxiv.org/abs/2501.02817v3)** | 2025-09-16 | <details><summary>Show</summary><p>Given a pair of time series, we study how the periodicity of one influences the periodicity of the other. There are several known methods to measure the similarity between a pair of time series, but we have yet to find any measures with theoretical stability results. Persistence homology has been utilized to construct a scoring function with theoretical guarantees of stability that quantifies the periodicity of a single univariate time series f1, denoted score(f1). Building on this concept, we propose a conditional periodicity score that quantifies the periodicity similarity of two univariate time series, denoted score(f1|f2), and derive theoretical stability results for the same. We prove stability of score(f1|f2) under orthogonal projection of the time series embeddings onto their first K principal components. We show that the change in our score is bounded by a function of the eigenvalues corresponding to the remaining (unused) N-K principal components and hence is small when the first K principal components capture most of the variation in the time series embeddings. We derive a lower bound on the embedding dimension to use in our pipeline which guarantees that any two such embeddings produce scores that are linearly within epsilon of each other. We present a procedure for computing conditional periodicity scores and implement it on several types of synthetic signals. We experimentally compare our similarity measure to the most-similar statistical measure of percent determinism (%DET) and show greater stability of score(f1|f2). We also compare both measures on several pairs of real time series describing monthly proportions of incoming calls to a police agency and highlight the decreased stability of %DET on the same.</p></details> |  |
| **[Causal Feedback Discovery using Convergence Cross Mapping on Sea Ice Data](http://arxiv.org/abs/2505.09001v3)** | 2025-09-16 | <details><summary>Show</summary><p>Identifying causal relationships in climate systems remains challenging due to nonlinear, coupled dynamics that limit the effectiveness of linear and stochastic causal discovery approaches. This study benchmarks Convergence Cross Mapping (CCM) against Granger causality, PCMCI, and VarLiNGAM using both synthetic datasets with ground truth causal links and 41 years of Arctic climate data (1979--2021). Unlike stochastic models that rely on autoregressive residual dependence, CCM leverages Takens' state-space reconstruction and delay-embedding to reconstruct attractor manifolds from time series. Cross mapping between reconstructed manifolds exploits deterministic signatures of causation, enabling the detection of weak and bidirectional causal links that linear models fail to resolve. Results demonstrate that CCM achieves higher specificity and fewer false positives on synthetic benchmarks, while maintaining robustness under observational noise and limited sample lengths. On Arctic data, CCM reveals significant causal interactions between sea ice extent and atmospheric variables like specific humidity, longwave radiation, and surface temperature with a $p$-value of $0.009$, supporting ice-albedo feedbacks and moisture-radiation couplings central to Arctic amplification. In contrast, stochastic approaches miss these nonlinear dependencies or infer spurious causal relations. This work establishes CCM as a robust causal inference tool for nonlinear climate dynamics and provides the first systematic benchmarking framework for method selection in climate research.</p></details> | <details><summary>In AC...</summary><p>In ACM Sigspatial Conference Workshop, 8 pages</p></details> |
| **[Vulnerability Patching Across Software Products and Software Components: A Case Study of Red Hat's Product Portfolio](http://arxiv.org/abs/2509.13117v1)** | 2025-09-16 | <details><summary>Show</summary><p>Motivated by software maintenance and the more recent concept of security debt, the paper presents a time series analysis of vulnerability patching of Red Hat's products and components between 1999 and 2024. According to the results based on segmented regression analysis, the amounts of vulnerable products and components have not been stable; a linear trend describes many of the series well. Nor do the amounts align well with trends characterizing vulnerabilities in general. There are also visible breakpoints indicating that the linear trend is not universally applicable and that the growing security debt may be stabilizing.</p></details> | <details><summary>Submi...</summary><p>Submitted to SecITC 2025</p></details> |
| **[Clustering methods for Categorical Time Series and Sequences : A scoping review](http://arxiv.org/abs/2509.07885v2)** | 2025-09-16 | <details><summary>Show</summary><p>Objective: To provide an overview of clustering methods for categorical time series (CTS), a data structure commonly found in epidemiology, sociology, biology, and marketing, and to support method selection in regards to data characteristics. Methods: We searched PubMed, Web of Science, and Google Scholar, from inception up to November 2024 to identify articles that propose and evaluate clustering techniques for CTS. Methods were classified according to three major families -- distance-based, feature-based, and model-based -- and assessed on their ability to handle data challenges such as variable sequence length, multivariate data, continuous time, missing data, time-invariant covariates, and large data volumes. Results: Out of 14607 studies, we included 124 articles describing 129 methods, spanning domains such as artificial intelligence, social sciences, and epidemiology. Distance-based methods, particularly those using Optimal Matching, were most prevalent, with 56 methods. We identified 28 model-based methods, which demonstrated superior flexibility for handling complex data structures such as multivariate data, continuous time and time-invariant covariates. We also recorded 45 feature-based approaches, which were on average more scalable but less flexible. A searchable Web application was developed to facilitate method selection based on dataset characteristics ( https://cts-clustering-scoping-review-7sxqj3sameqvmwkvnzfynz.streamlit.app/ ) Discussion: While distance-based methods dominate, model-based approaches offer the richest modeling potential but are less scalable. Feature-based methods favor performance over flexibility, with limited support for complex data structures. Conclusion: This review highlights methodological diversity and gaps in CTS clustering. The proposed typology aims to guide researchers in selecting methods for their specific use cases.</p></details> |  |
| **[Spatiotemporal graph neural process for reconstruction, extrapolation, and classification of cardiac trajectories](http://arxiv.org/abs/2509.12953v1)** | 2025-09-16 | <details><summary>Show</summary><p>We present a probabilistic framework for modeling structured spatiotemporal dynamics from sparse observations, focusing on cardiac motion. Our approach integrates neural ordinary differential equations (NODEs), graph neural networks (GNNs), and neural processes into a unified model that captures uncertainty, temporal continuity, and anatomical structure. We represent dynamic systems as spatiotemporal multiplex graphs and model their latent trajectories using a GNN-parameterized vector field. Given the sparse context observations at node and edge levels, the model infers a distribution over latent initial states and control variables, enabling both interpolation and extrapolation of trajectories. We validate the method on three synthetic dynamical systems (coupled pendulum, Lorenz attractor, and Kuramoto oscillators) and two real-world cardiac imaging datasets - ACDC (N=150) and UK Biobank (N=526) - demonstrating accurate reconstruction, extrapolation, and disease classification capabilities. The model accurately reconstructs trajectories and extrapolates future cardiac cycles from a single observed cycle. It achieves state-of-the-art results on the ACDC classification task (up to 99% accuracy), and detects atrial fibrillation in UK Biobank subjects with competitive performance (up to 67% accuracy). This work introduces a flexible approach for analyzing cardiac motion and offers a foundation for graph-based learning in structured biomedical spatiotemporal time-series data.</p></details> |  |
| **[FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers](http://arxiv.org/abs/2509.11109v2)** | 2025-09-16 | <details><summary>Show</summary><p>The embodied intelligence bridges the physical world and information space. As its typical physical embodiment, humanoid robots have shown great promise through robot learning algorithms in recent years. In this study, a hardware platform, including humanoid robot and exoskeleton-style teleoperation cabin, was developed to realize intuitive remote manipulation and efficient collection of anthropomorphic action data. To improve the perception representation of humanoid robot, an imitation learning framework, termed Frequency-Enhanced Wavelet-based Transformer (FEWT), was proposed, which consists of two primary modules: Frequency-Enhanced Efficient Multi-Scale Attention (FE-EMA) and Time-Series Discrete Wavelet Transform (TS-DWT). By combining multi-scale wavelet decomposition with the residual network, FE-EMA can dynamically fuse features from both cross-spatial and frequency-domain. This fusion is able to capture feature information across various scales effectively, thereby enhancing model robustness. Experimental performance demonstrates that FEWT improves the success rate of the state-of-the-art algorithm (Action Chunking with Transformers, ACT baseline) by up to 30% in simulation and by 6-12% in real-world.</p></details> |  |
| **[TimeCluster with PCA is Equivalent to Subspace Identification of Linear Dynamical Systems](http://arxiv.org/abs/2509.12895v1)** | 2025-09-16 | <details><summary>Show</summary><p>TimeCluster is a visual analytics technique for discovering structure in long multivariate time series by projecting overlapping windows of data into a low-dimensional space. We show that, when Principal Component Analysis (PCA) is chosen as the dimensionality reduction technique, this procedure is mathematically equivalent to classical linear subspace identification (block-Hankel matrix plus Singular Vector Decomposition (SVD)). In both approaches, the same low-dimensional linear subspace is extracted from the time series data. We first review the TimeCluster method and the theory of subspace system identification. Then we show that forming the sliding-window matrix of a time series yields a Hankel matrix, so applying PCA (via SVD) to this matrix recovers the same principal directions as subspace identification. Thus the cluster coordinates from TimeCluster coincide with the subspace identification methods. We present experiments on synthetic and real dynamical signals confirming that the two embeddings coincide. Finally, we explore and discuss future opportunities enabled by this equivalence, including forecasting from the identified state space, streaming/online extensions, incorporating and visualising external inputs and robust techniques for displaying underlying trends in corrupted data.</p></details> | 15 pages, 9 figures |
| **[A Novel Recurrent Neural Network Framework for Prediction and Treatment of Oncogenic Mutation Progression](http://arxiv.org/abs/2509.12732v1)** | 2025-09-16 | <details><summary>Show</summary><p>Despite significant medical advancements, cancer remains the second leading cause of death, with over 600,000 deaths per year in the US. One emerging field, pathway analysis, is promising but still relies on manually derived wet lab data, which is time-consuming to acquire. This work proposes an efficient, effective end-to-end framework for Artificial Intelligence (AI) based pathway analysis that predicts both cancer severity and mutation progression, thus recommending possible treatments. The proposed technique involves a novel combination of time-series machine learning models and pathway analysis. First, mutation sequences were isolated from The Cancer Genome Atlas (TCGA) Database. Then, a novel preprocessing algorithm was used to filter key mutations by mutation frequency. This data was fed into a Recurrent Neural Network (RNN) that predicted cancer severity. Then, the model probabilistically used the RNN predictions, information from the preprocessing algorithm, and multiple drug-target databases to predict future mutations and recommend possible treatments. This framework achieved robust results and Receiver Operating Characteristic (ROC) curves (a key statistical metric) with accuracies greater than 60%, similar to existing cancer diagnostics. In addition, preprocessing played an instrumental role in isolating important mutations, demonstrating that each cancer stage studied may contain on the order of a few-hundred key driver mutations, consistent with current research. Heatmaps based on predicted gene frequency were also generated, highlighting key mutations in each cancer. Overall, this work is the first to propose an efficient, cost-effective end-to-end framework for projecting cancer progression and providing possible treatments without relying on expensive, time-consuming wet lab work.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 11 figures, work originally done in 2022/2023 and was awarded as one of the Regeneron Science Talent Search Finalists in 2022</p></details> |
| **[Shape-to-Scale InSAR Adaptive Filtering and Phase Linking under Complex Elliptical Models](http://arxiv.org/abs/2509.12700v1)** | 2025-09-16 | <details><summary>Show</summary><p>Distributed scatterers in InSAR (DS-InSAR) processing are essential for retrieving surface deformation in areas lacking strong point targets. Conventional workflows typically involve selecting statistically homogeneous pixels based on amplitude similarity, followed by phase estimation under the complex circular Gaussian model. However, amplitude statistics primarily reflect the backscattering strength of surface targets and may not sufficiently capture differences in decorrelation behavior. For example, when distinct scatterers exhibit similar backscatter strength but differ in coherence, amplitude-based selection methods may fail to differentiate them. Moreover, CCG-based phase estimators may lack robustness and suffer performance degradation under non-Rayleigh amplitude fluctuations. Centered around scale-invariant second-order statistics, we propose ``Shape-to-Scale,'' a novel DS-InSAR framework. We first identify pixels that share a common angular scattering structure (``shape statistically homogeneous pixels'') with an angular consistency adaptive filter: a parametric selection method based on the complex angular central Gaussian distribution. Then, we introduce a complex generalized Gaussian-based phase estimation approach that is robust to potential non-Rayleigh scattering. Experiments on both simulated and SAR datasets show that the proposed framework improves coherence structure clustering and enhances phase estimation robustness. This work provides a unified and physically interpretable strategy for DS-InSAR processing and offers new insights for high-resolution SAR time series analysis.</p></details> |  |
| **[Leveraging Intermediate Representations of Time Series Foundation Models for Anomaly Detection](http://arxiv.org/abs/2509.12650v1)** | 2025-09-16 | <details><summary>Show</summary><p>Detecting anomalies in time series data is essential for the reliable operation of many real-world systems. Recently, time series foundation models (TSFMs) have emerged as a powerful tool for anomaly detection. However, existing methods typically rely on the final layer's representations of TSFMs, computing the anomaly score as a reconstruction or forecasting error via a task-specific head. Instead, we propose TimeRep, a novel anomaly detection approach that leverages the intermediate layer's representations of TSFMs, computing the anomaly score as the distance between these representations. Given a pre-trained TSFM, TimeRep selects the intermediate layer and patch-token position that yield the most informative representation. TimeRep forms a reference collection of intermediate representations from the training data and applies a core-set strategy to reduce its size while maintaining distributional coverage. During inference, TimeRep computes the anomaly score for incoming data by measuring the distance between its intermediate representations and those of the collection. To address concept drift, TimeRep integrates an adaptation mechanism that, at inference time, augments the collection exclusively with non-redundant intermediate representations from incoming data. We conducted extensive experiments on the UCR Anomaly Archive, which contains 250 univariate time series. TimeRep consistently outperforms a broad spectrum of state-of-the-art baselines, including non-DL, DL, and foundation model-based methods.</p></details> | 10 pages,8 figures |
| **[A Time Series Analysis of Assertions in the Linux Kernel](http://arxiv.org/abs/2412.19465v2)** | 2025-09-16 | <details><summary>Show</summary><p>Assertions are a classical and typical software development technique. These are extensively used also in operating systems and their kernels, including the Linux kernel. The paper fills a gap in existing knowledge by empirically examining the longitudinal evolution of assertion use in the Linux kernel. According to the results, the use of assertions that cause a kernel panic has slightly but not substantially decreased from the kernel's third to the sixth release series. At the same time, the use of softer assertion variants has increased; these do not cause a panic by default but instead produce warnings. With these time series results, the paper contributes to the existing but limited empirical knowledge base about operating system kernels and their long-term evolution.</p></details> | <details><summary>Proce...</summary><p>Proceedings of the 37th International Conference on Testing Software and Systems (ICTSS 2025), Limassol, Springer, pp. 3-15</p></details> |
| **[Cross-Modal Deep Metric Learning for Time Series Anomaly Detection](http://arxiv.org/abs/2509.12540v1)** | 2025-09-16 | <details><summary>Show</summary><p>To effectively address the issues of low sensitivity and high time consumption in time series anomaly detection, we propose an anomaly detection method based on cross-modal deep metric learning. A cross-modal deep metric learning feature clustering model is constructed, composed of an input layer, a triplet selection layer, and a loss function computation layer. The squared Euclidean distances between cluster centers are calculated, and a stochastic gradient descent strategy is employed to optimize the model and classify different time series features. The inner product of principal component direction vectors is used as a metric for anomaly measurement. The von Mises-Fisher (vMF) distribution is applied to describe the directional characteristics of time series data, and historical data is used to train and obtain evaluation parameters. By comparing the principal component direction vector of actual time series data with the threshold, anomaly detection is performed. Experimental results demonstrate that the proposed method accurately classifies time series data with different attributes, exhibits high sensitivity to anomalies, and achieves high detection accuracy, fast detection speed, and strong robustness.</p></details> |  |
| **[Diffusion-Based Generation and Imputation of Driving Scenarios from Limited Vehicle CAN Data](http://arxiv.org/abs/2509.12375v1)** | 2025-09-15 | <details><summary>Show</summary><p>Training deep learning methods on small time series datasets that also include corrupted samples is challenging. Diffusion models have shown to be effective to generate realistic and synthetic data, and correct corrupted samples through imputation. In this context, this paper focuses on generating synthetic yet realistic samples of automotive time series data. We show that denoising diffusion probabilistic models (DDPMs) can effectively solve this task by applying them to a challenging vehicle CAN-dataset with long-term data and a limited number of samples. Therefore, we propose a hybrid generative approach that combines autoregressive and non-autoregressive techniques. We evaluate our approach with two recently proposed DDPM architectures for time series generation, for which we propose several improvements. To evaluate the generated samples, we propose three metrics that quantify physical correctness and test track adherence. Our best model is able to outperform even the training data in terms of physical correctness, while showing plausible driving behavior. Finally, we use our best model to successfully impute physically implausible regions in the training data, thereby improving the data quality.</p></details> | <details><summary>Prepr...</summary><p>Preprint, Paper has been accepted at ITSC 2025</p></details> |
| **[Explainable Unsupervised Multi-Anomaly Detection and Temporal Localization in Nuclear Times Series Data with a Dual Attention-Based Autoencoder](http://arxiv.org/abs/2509.12372v1)** | 2025-09-15 | <details><summary>Show</summary><p>The nuclear industry is advancing toward more new reactor designs, with next-generation reactors expected to be smaller in scale and power output. These systems have the potential to produce large volumes of information in the form of multivariate time-series data, which could be used for enhanced real-time monitoring and control. In this context, the development of remote autonomous or semi-autonomous control systems for reactor operation has gained significant interest. A critical first step toward such systems is an accurate diagnostics module capable of detecting and localizing anomalies within the reactor system. Recent studies have proposed various ML and DL approaches for anomaly detection in the nuclear domain. Despite promising results, key challenges remain, including limited to no explainability, lack of access to real-world data, and scarcity of abnormal events, which impedes benchmarking and characterization. Most existing studies treat these methods as black boxes, while recent work highlights the need for greater interpretability of ML/DL outputs in safety-critical domains. Here, we propose an unsupervised methodology based on an LSTM autoencoder with a dual attention mechanism for characterization of abnormal events in a real-world reactor radiation area monitoring system. The framework includes not only detection but also localization of the event and was evaluated using real-world datasets of increasing complexity from the PUR-1 research reactor. The attention mechanisms operate in both the feature and temporal dimensions, where the feature attention assigns weights to radiation sensors exhibiting abnormal patterns, while time attention highlights the specific timesteps where irregularities occur, thus enabling localization. By combining the results, the framework can identify both the affected sensors and the duration of each anomaly within a single unified network.</p></details> |  |
| **[Dynamic Relational Priming Improves Transformer in Multivariate Time Series](http://arxiv.org/abs/2509.12196v1)** | 2025-09-15 | <details><summary>Show</summary><p>Standard attention mechanisms in transformers employ static token representations that remain unchanged across all pair-wise computations in each layer. This limits their representational alignment with the potentially diverse relational dynamics of each token-pair interaction. While they excel in domains with relatively homogeneous relationships, standard attention's static relational learning struggles to capture the diverse, heterogeneous inter-channel dependencies of multivariate time series (MTS) data--where different channel-pair interactions within a single system may be governed by entirely different physical laws or temporal dynamics. To better align the attention mechanism for such domain phenomena, we propose attention with dynamic relational priming (prime attention). Unlike standard attention where each token presents an identical representation across all of its pair-wise interactions, prime attention tailors each token dynamically (or per interaction) through learnable modulations to best capture the unique relational dynamics of each token pair, optimizing each pair-wise interaction for that specific relationship. This representational plasticity of prime attention enables effective extraction of relationship-specific information in MTS while maintaining the same asymptotic computational complexity as standard attention. Our results demonstrate that prime attention consistently outperforms standard attention across benchmarks, achieving up to 6.5\% improvement in forecasting accuracy. In addition, we find that prime attention achieves comparable or superior performance using up to 40\% less sequence length compared to standard attention, further demonstrating its superior relational modeling capabilities.</p></details> |  |
| **[A Time-Series Foundation Model by Universal Delay Embedding](http://arxiv.org/abs/2509.12080v1)** | 2025-09-15 | <details><summary>Show</summary><p>This study introduces Universal Delay Embedding (UDE), a pretrained foundation model designed to revolutionize time-series forecasting through principled integration of delay embedding representation and Koopman operator prediction. Leveraging Takens' embedding theorem, UDE as a dynamical representation of observed data constructs two-dimensional subspace patches from Hankel matrices, theoretically preserving dynamical and topological properties of underlying dynamical systems. Such patches are viewed as images, which can be efficiently processed by exploiting advanced deep learning technologies. Computationally, these patches further serve as tokens for learning a self-attention encoder, thus enabling accurate prediction of nonlinear time-series by a finite-dimensional Koopman operator in a linear manner in a latent space. Extensive evaluations across various benchmarks and real-world climate datasets demonstrate over 20% average reduction in mean squared error versus state-of-the-art foundation models, alongside superior generalization in fine-tuning scenarios. In particular, the learned dynamical representations and Koopman operator prediction forms from the patches exhibit exceptional interpretability, with consistent identification of topologically informative subspaces and robust encoding of domain-invariant dynamics, establishing UDE as a scalable, interpretable framework for universal time-series modeling and forecasting with broad scientific and industrial applicability.</p></details> |  |
| **[Robust Fetal Pose Estimation across Gestational Ages via Cross-Population Augmentation](http://arxiv.org/abs/2509.12062v1)** | 2025-09-15 | <details><summary>Show</summary><p>Fetal motion is a critical indicator of neurological development and intrauterine health, yet its quantification remains challenging, particularly at earlier gestational ages (GA). Current methods track fetal motion by predicting the location of annotated landmarks on 3D echo planar imaging (EPI) time-series, primarily in third-trimester fetuses. The predicted landmarks enable simplification of the fetal body for downstream analysis. While these methods perform well within their training age distribution, they consistently fail to generalize to early GAs due to significant anatomical changes in both mother and fetus across gestation, as well as the difficulty of obtaining annotated early GA EPI data. In this work, we develop a cross-population data augmentation framework that enables pose estimation models to robustly generalize to younger GA clinical cohorts using only annotated images from older GA cohorts. Specifically, we introduce a fetal-specific augmentation strategy that simulates the distinct intrauterine environment and fetal positioning of early GAs. Our experiments find that cross-population augmentation yields reduced variability and significant improvements across both older GA and challenging early GA cases. By enabling more reliable pose estimation across gestation, our work potentially facilitates early clinical detection and intervention in challenging 4D fetal imaging settings. Code is available at https://github.com/sebodiaz/cross-population-pose.</p></details> | Accepted MICCAI 2025 |
| **[Quantum Noise Tomography with Physics-Informed Neural Networks](http://arxiv.org/abs/2509.11911v1)** | 2025-09-15 | <details><summary>Show</summary><p>Characterizing the environmental interactions of quantum systems is a critical bottleneck in the development of robust quantum technologies. Traditional tomographic methods are often data-intensive and struggle with scalability. In this work, we introduce a novel framework for performing Lindblad tomography using Physics-Informed Neural Networks (PINNs). By embedding the Lindblad master equation directly into the neural network's loss function, our approach simultaneously learns the quantum state's evolution and infers the underlying dissipation parameters from sparse, time-series measurement data. Our results show that PINNs can reconstruct both the system dynamics and the functional form of unknown noise parameters, presenting a sample-efficient and scalable solution for quantum device characterization. Ultimately, our method produces a fully-differentiable digital twin of a noisy quantum system by learning its governing master equation.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 3 figures, Machine Learning and the Physical Sciences Workshop at the 39th conference on Neural Information Processing Systems (NeurIPS)</p></details> |
| **[Wavelet-SARIMA-Transformer: A Hybrid Model for Rainfall Forecasting](http://arxiv.org/abs/2509.11903v1)** | 2025-09-15 | <details><summary>Show</summary><p>This study develops and evaluates a novel hybridWavelet SARIMA Transformer, WST framework to forecast using monthly rainfall across five meteorological subdivisions of Northeast India over the 1971 to 2023 period. The approach employs the Maximal Overlap Discrete Wavelet Transform, MODWT with four wavelet families such as, Haar, Daubechies, Symlet, Coiflet etc. to achieve shift invariant, multiresolution decomposition of the rainfall series. Linear and seasonal components are modeled using Seasonal ARIMA, SARIMA, while nonlinear components are modeled by a Transformer network, and forecasts are reconstructed via inverse MODWT. Comprehensive validation using an 80 is to 20 train test split and multiple performance indices such as, RMSE, MAE, SMAPE, Willmotts d, Skill Score, Percent Bias, Explained Variance, and Legates McCabes E1 demonstrates the superiority of the Haar-based hybrid model, WHST. Across all subdivisions, WHST consistently achieved lower forecast errors, stronger agreement with observed rainfall, and unbiased predictions compared with stand alone SARIMA, stand-alone Transformer, and two-stage wavelet hybrids. Residual adequacy was confirmed through the Ljung Box test, while Taylor diagrams provided an integrated assessment of correlation, variance fidelity, and RMSE, further reinforcing the robustness of the proposed approach. The results highlight the effectiveness of integrating multiresolution signal decomposition with complementary linear and deep learning models for hydroclimatic forecasting. Beyond rainfall, the proposed WST framework offers a scalable methodology for forecasting complex environmental time series, with direct implications for flood risk management, water resources planning, and climate adaptation strategies in data-sparse and climate-sensitive regions.</p></details> |  |
| **[A Path Signature Framework for Detecting Creative Fatigue in Digital Advertising](http://arxiv.org/abs/2509.09758v2)** | 2025-09-15 | <details><summary>Show</summary><p>This paper introduces a novel framework for detecting advertising creative fatigue using path signature analysis, a geometric approach from rough path theory not previously applied in marketing. Creative fatigue - the decline in advertising effectiveness over time - poses a major risk to digital media spend. Our method transforms performance time-series into geometric paths, extracting high-dimensional signatures to capture complex dynamics: volatility shifts, trend reversals, and non-linear decay. Unlike traditional statistical methods, this approach detects subtle, multi-scale changes. We validate the framework using synthetic datasets replicating documented fatigue patterns from marketing literature. Results show superior early detection, enabling actionable insights before significant budget loss. A novel financial impact model quantifies opportunity costs from delayed detection, while computational analysis confirms linear scalability for real-time monitoring of large creative portfolios.</p></details> | version 2 |
| **[TemporalFED: Detecting Cyberattacks in Industrial Time-Series Data Using Decentralized Federated Learning](http://arxiv.org/abs/2308.03554v2)** | 2025-09-15 | <details><summary>Show</summary><p>Industry 4.0 has brought numerous advantages, such as increasing productivity through automation. However, it also presents major cybersecurity issues such as cyberattacks affecting industrial processes. Federated Learning (FL) combined with time-series analysis is a promising cyberattack detection mechanism proposed in the literature. However, the fact of having a single point of failure and network bottleneck are critical challenges that need to be tackled. Thus, this article explores the benefits of the Decentralized Federated Learning (DFL) in terms of cyberattack detection and resource consumption. The work presents TemporalFED, a software module for detecting anomalies in industrial environments using FL paradigms and time series. TemporalFED incorporates three components: Time Series Conversion, Feature Engineering, and Time Series Stationary Conversion. To evaluate TemporalFED, it was deployed on Fedstellar, a DFL framework. Then, a pool of experiments measured the detection performance and resource consumption in a chemical gas industrial environment with different time-series configurations, FL paradigms, and topologies. The results showcase the superiority of the configuration utilizing DFL and Semi-Decentralized Federated Learning (SDFL) paradigms, along with a fully connected topology, which achieved the best performance in anomaly detection. Regarding resource consumption, the configuration without feature engineering employed less bandwidth, CPU, and RAM than other configurations.</p></details> |  |
| **[Topology Structure Optimization of Reservoirs Using GLMY Homology](http://arxiv.org/abs/2509.11612v1)** | 2025-09-15 | <details><summary>Show</summary><p>Reservoir is an efficient network for time series processing. It is well known that network structure is one of the determinants of its performance. However, the topology structure of reservoirs, as well as their performance, is hard to analyzed, due to the lack of suitable mathematical tools. In this paper, we study the topology structure of reservoirs using persistent GLMY homology theory, and develop a method to improve its performance. Specifically, it is found that the reservoir performance is closely related to the one-dimensional GLMY homology groups. Then, we develop a reservoir structure optimization method by modifying the minimal representative cycles of one-dimensional GLMY homology groups. Finally, by experiments, it is validated that the performance of reservoirs is jointly influenced by the reservoir structure and the periodicity of the dataset.</p></details> |  |
| **[A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models](http://arxiv.org/abs/2509.11575v1)** | 2025-09-15 | <details><summary>Show</summary><p>Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (https://github.com/blacksnail789521/Time-Series-Reasoning-Survey). Evaluation practices that keep evidence visible and temporally aligned are highlighted, and guidance is distilled on matching topology to uncertainty, grounding with observable artifacts, planning for shift and streaming, and treating cost and latency as design budgets. We emphasize that reasoning structures must balance capacity for grounding and self-correction against computational cost and reproducibility, while future progress will likely depend on benchmarks that tie reasoning quality to utility and on closed-loop testbeds that trade off cost and risk under shift-aware, streaming, and long-horizon settings. Taken together, these directions mark a shift from narrow accuracy toward reliability at scale, enabling systems that not only analyze but also understand, explain, and act on dynamic worlds with traceable evidence and credible outcomes.</p></details> | <details><summary>This ...</summary><p>This paper is currently under review</p></details> |
| **[Association between Air Pollutants and Hospitalizations for Cardiovascular Diseases: Time-Series Analysis in So Paulo, 2010-2019](http://arxiv.org/abs/2509.11546v1)** | 2025-09-15 | <details><summary>Show</summary><p>Cardiovascular diseases (CVD) remain one of the leading causes of hospitalization in Brazil. Exposure to air pollutants such as PM$_{10}$ $\mu$m, NO$_2$, and SO$_2$ has been associated with the worsening of these diseases, especially in urban areas. This study evaluated the association between the daily concentration of these pollutants and daily hospitalizations for acute myocardial infarction and cerebrovascular diseases in S\~ao Paulo (2010-2019), using generalized additive models with a lag of 0 to 4 days. Two approaches for choosing the degrees of freedom in temporal smoothing were compared: based on pollutant prediction and based on outcome prediction (hospitalizations). Data were obtained from official government databases. The modeling used the quasi-Poisson family in R software (v. 4.4.0). Models with exposure-based smoothing generated more consistent estimates. For PM10{\mu}m, the cumulative risk estimate for exposure was 1.08%, while for hospitalization, it was 1.20%. For NO$_2$, the estimated risk was 1.47% (exposure) versus 1.33% (hospitalization). For SO$_2$, a striking difference was observed: 7.66% (exposure) versus 14.31% (hospitalization). The significant lags were on days 0, 1, and 2. The results show that smoothing based on outcome prediction can generate bias, masking the true effect of pollutants. The appropriate choice of df in the smoothing function is crucial. Smoothing by the pollutant series was more robust and accurate, contributing to methodological improvements in time-series studies and reinforcing the importance of public policies for pollution control.</p></details> | <details><summary>18 pa...</summary><p>18 pages with 4 figures</p></details> |
| **[Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning](http://arxiv.org/abs/2509.11420v1)** | 2025-09-14 | <details><summary>Show</summary><p>Developing professional, structured reasoning on par with human financial analysts and traders remains a central challenge in AI for finance, where markets demand interpretability and trust. Traditional time-series models lack explainability, while LLMs face challenges in turning natural-language analysis into disciplined, executable trades. Although reasoning LLMs have advanced in step-by-step planning and verification, their application to risk-sensitive financial decisions is underexplored. We present Trading-R1, a financially-aware model that incorporates strategic thinking and planning for comprehensive thesis composition, facts-grounded analysis, and volatility-adjusted decision making. Trading-R1 aligns reasoning with trading principles through supervised fine-tuning and reinforcement learning with a three-stage easy-to-hard curriculum. Training uses Tauric-TR1-DB, a 100k-sample corpus spanning 18 months, 14 equities, and five heterogeneous financial data sources. Evaluated on six major equities and ETFs, Trading-R1 demonstrates improved risk-adjusted returns and lower drawdowns compared to both open-source and proprietary instruction-following models as well as reasoning models. The system generates structured, evidence-based investment theses that support disciplined and interpretable trading decisions. Trading-R1 Terminal will be released at https://github.com/TauricResearch/Trading-R1.</p></details> | <details><summary>Tauri...</summary><p>Tauric Research: https://github.com/TauricResearch</p></details> |
| **[Improved Classification of Nitrogen Stress Severity in Plants Under Combined Stress Conditions Using Spatio-Temporal Deep Learning Framework](http://arxiv.org/abs/2509.06625v2)** | 2025-09-14 | <details><summary>Show</summary><p>Plants in their natural habitats endure an array of interacting stresses, both biotic and abiotic, that rarely occur in isolation. Nutrient stress-particularly nitrogen deficiency-becomes even more critical when compounded with drought and weed competition, making it increasingly difficult to distinguish and address its effects. Early detection of nitrogen stress is therefore crucial for protecting plant health and implementing effective management strategies. This study proposes a novel deep learning framework to accurately classify nitrogen stress severity in a combined stress environment. Our model uses a unique blend of four imaging modalities-RGB, multispectral, and two infrared wavelengths-to capture a wide range of physiological plant responses from canopy images. These images, provided as time-series data, document plant health across three levels of nitrogen availability (low, medium, and high) under varying water stress and weed pressures. The core of our approach is a spatio-temporal deep learning pipeline that merges a Convolutional Neural Network (CNN) for extracting spatial features from images with a Long Short-Term Memory (LSTM) network to capture temporal dependencies. We also devised and evaluated a spatial-only CNN pipeline for comparison. Our CNN-LSTM pipeline achieved an impressive accuracy of 98%, impressively surpassing the spatial-only model's 80.45% and other previously reported machine learning method's 76%. These results bring actionable insights based on the power of our CNN-LSTM approach in effectively capturing the subtle and complex interactions between nitrogen deficiency, water stress, and weed pressure. This robust platform offers a promising tool for the timely and proactive identification of nitrogen stress severity, enabling better crop management and improved plant health.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 8 figures, 7 Tables</p></details> |
| **[Next-Generation Reservoir Computing for Dynamical Inference](http://arxiv.org/abs/2509.11338v1)** | 2025-09-14 | <details><summary>Show</summary><p>We present a simple and scalable implementation of next-generation reservoir computing for modeling dynamical systems from time series data. Our approach uses a pseudorandom nonlinear projection of time-delay embedded input, allowing an arbitrary dimension of the feature space, thus providing a flexible alternative to the polynomial-based projections used in previous next-generation reservoir computing variants. We apply the method to benchmark tasks -- including attractor reconstruction and bifurcation diagram estimation -- using only partial and noisy observations. We also include an exploratory example of estimating asymptotic oscillation phases. The models remain stable over long rollouts and generalize beyond training data. This framework enables the precise control of system state and is well suited for surrogate modeling and digital twin applications.</p></details> | 10 pages, 10 figures |
| **[Parameter estimation for fractional autoregressive process with periodic structure](http://arxiv.org/abs/2503.20736v2)** | 2025-09-14 | <details><summary>Show</summary><p>This paper introduces a new periodic fractional autoregressive process (PFAR) driven by fractional Gaussian noise (fGn) to model time series of precipitation evapotranspiration. Compared with the similar model in [\emph{Water Resources Research}, \textbf{20} (1984) 1898--1908], the new model incorporates a periodic structure via specialized varying coefficients and captures long memory and rough voltality through fGn for $0<H<1$, rather than via fractional differencing. In this work, Generalized Least Squares Estimation (GLSE) and the GPH method are employed to construct an initial estimator for the joint estimation of model parameters. A One-Step procedure is then used to obtain a more asymptotically efficient estimator. The paper proves that both estimators are consistent and asymptotically normal, and their performance is demonstrated via Monte Carlo simulations with finite-size samples. Simulation studies suggest that, while both estimation methods can accurately estimate the model parameters, the One-Step estimator outperforms the initial estimator.</p></details> |  |
| **[Rumor Detection by Multi-task Suffix Learning based on Time-series Dual Sentiments](http://arxiv.org/abs/2502.14383v2)** | 2025-09-14 | <details><summary>Show</summary><p>The widespread dissemination of rumors on social media has a significant impact on people's lives, potentially leading to public panic and fear. Rumors often evoke specific sentiments, resonating with readers and prompting sharing. To effectively detect and track rumors, it is essential to observe the fine-grained sentiments of both source and response message pairs as the rumor evolves over time. However, current rumor detection methods fail to account for this aspect. In this paper, we propose MSuf, the first multi-task suffix learning framework for rumor detection and tracking using time series dual (coupled) sentiments. MSuf includes three modules: (1) an LLM to extract sentiment intensity features and sort them chronologically; (2) a module that fuses the sorted sentiment features with their source text word embeddings to obtain an aligned embedding; (3) two hard prompts are combined with the aligned vector to perform rumor detection and sentiment analysis using one frozen LLM. MSuf effectively enhances the performance of LLMs for rumor detection with only minimal parameter fine-tuning. Evaluating MSuf on four rumor detection benchmarks, we find significant improvements compared to other emotion-based methods.</p></details> | work in progress |
| **[Learning Chaotic Dynamics with Neuromorphic Network Dynamics](http://arxiv.org/abs/2506.10773v2)** | 2025-09-14 | <details><summary>Show</summary><p>This study investigates how dynamical systems may be learned and modelled with a neuromorphic network which is itself a dynamical system. The neuromorphic network used in this study is based on a complex electrical circuit comprised of memristive elements that produce neuro-synaptic nonlinear responses to input electrical signals. To determine how computation may be performed using the physics of the underlying system, the neuromorphic network was simulated and evaluated on autonomous prediction of a multivariate chaotic time series, implemented with a reservoir computing framework. Through manipulating only input electrodes and voltages, optimal nonlinear dynamical responses were found when input voltages maximise the number of memristive components whose internal dynamics explore the entire dynamical range of the memristor model. Increasing the network coverage with the input electrodes was found to suppress other nonlinear responses that are less conducive to learning. These results provide valuable insights into how a physical neuromorphic network device can be feasibly optimised for learning complex dynamical systems using only external control parameters.</p></details> | 42 pages, 24 figures |
| **[Maximum diversity, weighting and invariants of time series](http://arxiv.org/abs/2509.11146v1)** | 2025-09-14 | <details><summary>Show</summary><p>Magnitude, obtained as a special case of Euler characteristic of enriched category, represents a sense of the size of metric spaces and is related to classical notions such as cardinality, dimension, and volume. While the studies have explained the meaning of magnitude from various perspectives, continuity also gives a valuable view of magnitude. Based on established results about continuity of magnitude and maximum diversity, this article focuses on continuity of weighting, a distribution whose totality is magnitude, and its variation corresponding to maximum diversity. Meanwhile, recent studies also illuminated the connection between magnitude and data analysis by applying magnitude theory to point clouds representing the data or the set of model parameters. This article will also provide an application for time series analysis by introducing a new kind of invariants of periodic time series, where the invariance follows directly from the continuity results. As a use-case, a simple machine learning experiment is conducted with real-world data, in which the suggested invariants improved the performance.</p></details> |  |
| **[Large-Scale Curve Time Series with Common Stochastic Trends](http://arxiv.org/abs/2509.11060v1)** | 2025-09-14 | <details><summary>Show</summary><p>This paper studies high-dimensional curve time series with common stochastic trends. A dual functional factor model structure is adopted with a high-dimensional factor model for the observed curve time series and a low-dimensional factor model for the latent curves with common trends. A functional PCA technique is applied to estimate the common stochastic trends and functional factor loadings. Under some regularity conditions we derive the mean square convergence and limit distribution theory for the developed estimates, allowing the dimension and sample size to jointly diverge to infinity. We propose an easy-to-implement criterion to consistently select the number of common stochastic trends and further discuss model estimation when the nonstationary factors are cointegrated. Extensive Monte-Carlo simulations and two empirical applications to large-scale temperature curves in Australia and log-price curves of S&P 500 stocks are conducted, showing finite-sample performance and providing practical implementations of the new methodology.</p></details> |  |
| **[Deep Learning based Moving Target Defence for Federated Learning against Poisoning Attack in MEC Systems with a 6G Wireless Model](http://arxiv.org/abs/2509.10914v1)** | 2025-09-13 | <details><summary>Show</summary><p>Collaboration opportunities for devices are facilitated with Federated Learning (FL). Edge computing facilitates aggregation at edge and reduces latency. To deal with model poisoning attacks, model-based outlier detection mechanisms may not operate efficiently with hetereogenous models or in recognition of complex attacks. This paper fosters the defense line against model poisoning attack by exploiting device-level traffic analysis to anticipate the reliability of participants. FL is empowered with a topology mutation strategy, as a Moving Target Defence (MTD) strategy to dynamically change the participants in learning. Based on the adoption of recurrent neural networks for time-series analysis of traffic and a 6G wireless model, optimization framework for MTD strategy is given. A deep reinforcement mechanism is provided to optimize topology mutation in adaption with the anticipated Byzantine status of devices and the communication channel capabilities at devices. For a DDoS attack detection application and under Botnet attack at devices level, results illustrate acceptable malicious models exclusion and improvement in recognition time and accuracy.</p></details> |  |
| **[Branched Broomrape Detection in Tomato Farms Using Satellite Imagery and Time-Series Analysis](http://arxiv.org/abs/2509.10804v1)** | 2025-09-13 | <details><summary>Show</summary><p>Branched broomrape (Phelipanche ramosa (L.) Pomel) is a chlorophyll-deficient parasitic plant that threatens tomato production by extracting nutrients from the host, with reported yield losses up to 80 percent. Its mostly subterranean life cycle and prolific seed production (more than 200,000 seeds per plant, viable for up to 20 years) make early detection essential. We present an end-to-end pipeline that uses Sentinel-2 imagery and time-series analysis to identify broomrape-infested tomato fields in California. Regions of interest were defined from farmer-reported infestations, and images with less than 10 percent cloud cover were retained. We processed 12 spectral bands and sun-sensor geometry, computed 20 vegetation indices (e.g., NDVI, NDMI), and derived five plant traits (Leaf Area Index, Leaf Chlorophyll Content, Canopy Chlorophyll Content, Fraction of Absorbed Photosynthetically Active Radiation, and Fractional Vegetation Cover) using a neural network calibrated with ground-truth and synthetic data. Trends in Canopy Chlorophyll Content delineated transplanting-to-harvest periods, and phenology was aligned using growing degree days. Vegetation pixels were segmented and used to train a Long Short-Term Memory (LSTM) network on 18,874 pixels across 48 growing-degree-day time points. The model achieved 88 percent training accuracy and 87 percent test accuracy, with precision 0.86, recall 0.92, and F1 0.89. Permutation feature importance ranked NDMI, Canopy Chlorophyll Content, FAPAR, and a chlorophyll red-edge index as most informative, consistent with the physiological effects of infestation. Results show the promise of satellite-driven time-series modeling for scalable detection of parasitic stress in tomato farms.</p></details> | <details><summary>Autho...</summary><p>Author-accepted version. Published in Proceedings of SPIE Defense + Commercial Sensing 2025, Autonomous Air and Ground Sensing Systems for Agricultural Optimization and Phenotyping X (Vol. 13475), Paper 134750U. Official version: https://doi.org/10.1117/12.3059998</p></details> |
| **[Why Bonds Fail Differently? Explainable Multimodal Learning for Multi-Class Default Prediction](http://arxiv.org/abs/2509.10802v1)** | 2025-09-13 | <details><summary>Show</summary><p>In recent years, China's bond market has seen a surge in defaults amid regulatory reforms and macroeconomic volatility. Traditional machine learning models struggle to capture financial data's irregularity and temporal dependencies, while most deep learning models lack interpretability-critical for financial decision-making. To tackle these issues, we propose EMDLOT (Explainable Multimodal Deep Learning for Time-series), a novel framework for multi-class bond default prediction. EMDLOT integrates numerical time-series (financial/macroeconomic indicators) and unstructured textual data (bond prospectuses), uses Time-Aware LSTM to handle irregular sequences, and adopts soft clustering and multi-level attention to boost interpretability. Experiments on 1994 Chinese firms (2015-2024) show EMDLOT outperforms traditional (e.g., XGBoost) and deep learning (e.g., LSTM) benchmarks in recall, F1-score, and mAP, especially in identifying default/extended firms. Ablation studies validate each component's value, and attention analyses reveal economically intuitive default drivers. This work provides a practical tool and a trustworthy framework for transparent financial risk modeling.</p></details> |  |
| **[Using LLMs for Late Multimodal Sensor Fusion for Activity Recognition](http://arxiv.org/abs/2509.10729v1)** | 2025-09-12 | <details><summary>Show</summary><p>Sensor data streams provide valuable information around activities and context for downstream applications, though integrating complementary information can be challenging. We show that large language models (LLMs) can be used for late fusion for activity classification from audio and motion time series data. We curated a subset of data for diverse activity recognition across contexts (e.g., household activities, sports) from the Ego4D dataset. Evaluated LLMs achieved 12-class zero- and one-shot classification F1-scores significantly above chance, with no task-specific training. Zero-shot classification via LLM-based fusion from modality-specific models can enable multimodal temporal applications where there is limited aligned training data for learning a shared embedding space. Additionally, LLM-based fusion can enable model deploying without requiring additional memory and computation for targeted application-specific multimodal models.</p></details> | <details><summary>Prepr...</summary><p>Preprint, under review</p></details> |
| **[Continuum Attention for Neural Operators](http://arxiv.org/abs/2406.06486v3)** | 2025-09-12 | <details><summary>Show</summary><p>Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces. In this paper, we state and prove the first universal approximation result for transformer neural operators, using only a slight modification of the architecture implemented in practice. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.</p></details> |  |
| **[Modelling Under-Reported Data: Pitfalls of Nave Approaches and a New Statistical Framework for Epidemic Curve Reconstruction](http://arxiv.org/abs/2509.10668v1)** | 2025-09-12 | <details><summary>Show</summary><p>Count-valued autoregressions are widely used to analyse time-series of reported infectious-disease cases because of their close connection with discrete-time transmission models. However, when such models are applied directly to under-reported case counts, their mechanistic interpretation can break down. We establish new theoretical results quantifying the consequences of ignoring under-reporting in these models. To address this issue, reported cases are often modelled as a binomially thinned version of an underlying count process, but such models are difficult to fit because the unobserved true counts are serially correlated and integer-valued. We develop a new statistical framework for under-reported infectious-disease data that uses a normal-normal approximation to a broad class of thinned count autoregressions and then accurately maps this continuous process back to the integers. Through simulations and applications to rotavirus incidence in a German state and Covid-19 incidence in English conurbations, we demonstrate that our approach both retains the mechanistic appeal of thinned autoregressions and substantially simplifies inference.</p></details> |  |
| **[Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](http://arxiv.org/abs/2508.05210v2)** | 2025-09-12 | <details><summary>Show</summary><p>Accurate prediction of the Rate of Penetration (ROP) is pivotal for drilling optimization, yet it remains a persistent challenge due to the nonlinear, dynamic, and heterogeneous nature of drilling data. This study introduces a novel hybrid deep learning architecture in which input data are first processed through a customized Long Short-Term Memory (LSTM) network to capture multi-scale temporal dependencies aligned with drilling operational cycles, and the resulting features are subsequently refined by an Enhanced Transformer encoder with drilling-specific positional encodings and real-time optimization. Concurrently, the same input is directed to a Time-Series Mixer (TS-Mixer) block that enables efficient cross-feature modeling of static and categorical attributes such as lithology indices and mud properties. The outputs from the enhanced Transformer and TS-Mixer are concatenated, after which an adaptive attention selectively emphasizes the most informative feature representations for accurate ROP prediction. The proposed framework fuses sequential memory, static feature interactions, global contextual learning, and dynamic feature weighting, providing a comprehensive solution to the heterogeneous and event-driven nature of drilling dynamics. Evaluation on a real-world drilling dataset demonstrates benchmark-leading performance, achieving an Rsqaure of 0.9988 and a MAPE of 1.447%, significantly surpassing standalone and hybrid baselines. Model interpretability is achieved through SHAP and LIME, and comparisons between actual and predicted curves, along with bias checks, confirm the accuracy and fairness of the model across various scenarios. This advanced hybrid approach enables dependable real-time ROP prediction, supporting the development of intelligent, cost-effective drilling optimization systems with significant operational benefits.</p></details> | <details><summary>35 Pa...</summary><p>35 Pages, 19 Figures, 9 Tables</p></details> |
| **[pySigLib -- Fast Signature-Based Computations on CPU and GPU](http://arxiv.org/abs/2509.10613v1)** | 2025-09-12 | <details><summary>Show</summary><p>Signature-based methods have recently gained significant traction in machine learning for sequential data. In particular, signature kernels have emerged as powerful discriminators and training losses for generative models on time-series, notably in quantitative finance. However, existing implementations do not scale to the dataset sizes and sequence lengths encountered in practice. We present pySigLib, a high-performance Python library offering optimised implementations of signatures and signature kernels on CPU and GPU, fully compatible with PyTorch's automatic differentiation. Beyond an efficient software stack for large-scale signature-based computation, we introduce a novel differentiation scheme for signature kernels that delivers accurate gradients at a fraction of the runtime of existing libraries.</p></details> |  |
| **[ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](http://arxiv.org/abs/2509.10324v1)** | 2025-09-12 | <details><summary>Show</summary><p>This paper proposes a simple yet effective convolutional module for long-term time series forecasting. The proposed block, inspired by the Auto-Regressive Integrated Moving Average (ARIMA) model, consists of two convolutional components: one for capturing the trend (autoregression) and the other for refining local variations (moving average). Unlike conventional ARIMA, which requires iterative multi-step forecasting, the block directly performs multi-step forecasting, making it easily extendable to multivariate settings. Experiments on nine widely used benchmark datasets demonstrate that our method ARMA achieves competitive accuracy, particularly on datasets exhibiting strong trend variations, while maintaining architectural simplicity. Furthermore, analysis shows that the block inherently encodes absolute positional information, suggesting its potential as a lightweight replacement for positional embeddings in sequential models.</p></details> |  |
| **[GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](http://arxiv.org/abs/2509.10308v1)** | 2025-09-12 | <details><summary>Show</summary><p>In the aftermath of disasters, many institutions worldwide face challenges in continually monitoring changes in disaster risk, limiting the ability of key decision-makers to assess progress towards the UN Sendai Framework for Disaster Risk Reduction 2015-2030. While numerous efforts have substantially advanced the large-scale modeling of hazard and exposure through Earth observation and data-driven methods, progress remains limited in modeling another equally important yet challenging element of the risk equation: physical vulnerability. To address this gap, we introduce Graph Categorical Structured Variational Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for modeling physical vulnerability by integrating deep learning, graph representation, and categorical probabilistic inference, using time-series satellite-derived datasets and prior expert belief systems. We introduce a weakly supervised first-order transition matrix that reflects the changes in the spatiotemporal distribution of physical vulnerability in two disaster-stricken and socioeconomically disadvantaged areas: (1) the cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the mudslide-affected city of Freetown in Sierra Leone. Our work reveals post-disaster regional dynamics in physical vulnerability, offering valuable insights into localized spatiotemporal auditing and sustainable strategies for post-disaster risk reduction.</p></details> | <details><summary>Accep...</summary><p>Accepted full paper at the 8th International Disaster and Risk Conference, IDRC 2025 | Keywords: weakly supervised, graph deep learning, categorical distribution, physical vulnerability, remote sensing, spatiotemporal disaster risk, transition matrix | The data and code are respectively available at https://doi.org/10.5281/zenodo.16656471 and https://github.com/riskaudit/GraphCSVAE</p></details> |
| **[Data-Driven Discovery of Mobility Periodicity for Understanding Urban Systems](http://arxiv.org/abs/2508.03747v2)** | 2025-09-12 | <details><summary>Show</summary><p>Human mobility regularity is crucial for understanding urban dynamics and informing decision-making processes. This study first quantifies the periodicity in complex human mobility data as a sparse identification of dominant positive auto-correlations in time series autoregression and then discovers periodic patterns. We apply the framework to large-scale metro passenger flow data in Hangzhou, China and multi-modal mobility data in New York City and Chicago, USA, revealing the interpretable weekly periodicity across different spatial locations over past several years. The analysis of ridesharing data from 2019 to 2024 demonstrates the disruptive impact of the pandemic on mobility regularity and the subsequent recovery trends. In 2024, the periodic mobility patterns of ridesharing, taxi, subway, and bikesharing in Manhattan uncover the regularity and variability of these travel modes. Our findings highlight the potential of interpretable machine learning to discover spatiotemporal mobility patterns and offer a valuable tool for understanding urban systems.</p></details> |  |
| **[Echo State and Band-pass Networks with aqueous memristors: leaky reservoir computing with a leaky substrate](http://arxiv.org/abs/2505.13451v2)** | 2025-09-12 | <details><summary>Show</summary><p>Recurrent Neural Networks (RNN) are extensively employed for processing sequential data such as time series. Reservoir computing (RC) has drawn attention as an RNN framework due to its fixed network that does not require training, making it an attractive platform for hardware based machine learning. We establish an explicit correspondence between the well-established mathematical RC implementations of Echo State Networks and Band-pass Networks with Leaky Integrator nodes on the one hand and a physical circuit containing iontronic simple volatile memristors on the other. These aqueous iontronic devices employ ion transport through water as signal carriers, and feature a voltage-dependent (memory) conductance. The activation function and the dynamics of the Leaky Integrator nodes naturally materialise as the (dynamic) conductance properties of iontronic memristors, while a simple fixed local current-to-voltage update rule at the memristor terminals facilitates the relevant matrix coupling between nodes. We process various time series, including pressure data from simulated airways during breathing that can be directly fed into the network due to the intrinsic responsiveness of iontronic devices to applied pressures. We accomplish this by employing established physical equations of motion of iontronic memristors for the internal dynamics of the circuit.</p></details> |  |
| **[MAESTRO: Multi-modal Adaptive Estimation for Temporal Respiratory Disease Outbreak](http://arxiv.org/abs/2509.08578v2)** | 2025-09-12 | <details><summary>Show</summary><p>Timely and robust influenza incidence forecasting is critical for public health decision-making. This paper presents MAESTRO (Multi-modal Adaptive Estimation for Temporal Respiratory Disease Outbreak), a novel, unified framework that synergistically integrates advanced spectro-temporal modeling with multi-modal data fusion, including surveillance, web search trends, and meteorological data. By adaptively weighting heterogeneous data sources and decomposing complex time series patterns, the model achieves robust and accurate forecasts. Evaluated on over 11 years of Hong Kong influenza data (excluding the COVID-19 period), MAESTRO demonstrates state-of-the-art performance, achieving a superior model fit with an R-square of 0.956. Extensive ablations confirm the significant contributions of its multi-modal and spectro-temporal components. The modular and reproducible pipeline is made publicly available to facilitate deployment and extension to other regions and pathogens, presenting a powerful tool for epidemiological forecasting.</p></details> |  |
| **[Multivariate Long-term Time Series Forecasting with Fourier Neural Filter](http://arxiv.org/abs/2506.09174v2)** | 2025-09-12 | <details><summary>Show</summary><p>Multivariate long-term time series forecasting has been suffering from the challenge of capturing both temporal dependencies within variables and spatial correlations across variables simultaneously. Current approaches predominantly repurpose backbones from natural language processing or computer vision (e.g., Transformers), which fail to adequately address the unique properties of time series (e.g., periodicity). The research community lacks a dedicated backbone with temporal-specific inductive biases, instead relying on domain-agnostic backbones supplemented with auxiliary techniques (e.g., signal decomposition). We introduce FNF as the backbone and DBD as the architecture to provide excellent learning capabilities and optimal learning pathways for spatio-temporal modeling, respectively. Our theoretical analysis proves that FNF unifies local time-domain and global frequency-domain information processing within a single backbone that extends naturally to spatial modeling, while information bottleneck theory demonstrates that DBD provides superior gradient flow and representation capacity compared to existing unified or sequential architectures. Our empirical evaluation across 11 public benchmark datasets spanning five domains (energy, meteorology, transportation, environment, and nature) confirms state-of-the-art performance with consistent hyperparameter settings. Notably, our approach achieves these results without any auxiliary techniques, suggesting that properly designed neural architectures can capture the inherent properties of time series, potentially transforming time series modeling in scientific and industrial applications.</p></details> |  |
| **[Sparse Coding Representation of 2-way Data](http://arxiv.org/abs/2509.10033v1)** | 2025-09-12 | <details><summary>Show</summary><p>Sparse dictionary coding represents signals as linear combinations of a few dictionary atoms. It has been applied to images, time series, graph signals and multi-way spatio-temporal data by jointly employing temporal and spatial dictionaries. Data-agnostic analytical dictionaries, such as the discrete Fourier transform, wavelets and graph Fourier, have seen wide adoption due to efficient implementations and good practical performance. On the other hand, dictionaries learned from data offer sparser and more accurate solutions but require learning of both the dictionaries and the coding coefficients. This becomes especially challenging for multi-dictionary scenarios since encoding coefficients correspond to all atom combinations from the dictionaries. To address this challenge, we propose a low-rank coding model for 2-dictionary scenarios and study its data complexity. Namely, we establish a bound on the number of samples needed to learn dictionaries that generalize to unseen samples from the same distribution. We propose a convex relaxation solution, called AODL, whose exact solution we show also solves the original problem. We then solve this relaxation via alternating optimization between the sparse coding matrices and the learned dictionaries, which we prove to be convergent. We demonstrate its quality for data reconstruction and missing value imputation in both synthetic and real-world datasets. For a fixed reconstruction quality, AODL learns up to 90\% sparser solutions compared to non-low-rank and analytical (fixed) dictionary baselines. In addition, the learned dictionaries reveal interpretable insights into patterns present within the samples used for training.</p></details> |  |
| **[Semi-Supervised Learning for Dose Prediction in Targeted Radionuclide: A Synthetic Data Study](http://arxiv.org/abs/2503.05367v2)** | 2025-09-12 | <details><summary>Show</summary><p>Targeted Radionuclide Therapy (TRT) is a modern strategy in radiation oncology that aims to administer a potent radiation dose specifically to cancer cells using cancer-targeting radiopharmaceuticals. Accurate radiation dose estimation tailored to individual patients is crucial. Deep learning, particularly with pre-therapy imaging, holds promise for personalizing TRT doses. However, current methods require large time series of SPECT imaging, which is hardly achievable in routine clinical practice, and thus raises issues of data availability. Our objective is to develop a semi-supervised learning (SSL) solution to personalize dosimetry using pre-therapy images. The aim is to develop an approach that achieves accurate results when PET/CT images are available, but are associated with only a few post-therapy dosimetry data provided by SPECT images. In this work, we introduce an SSL method using a pseudo-label generation approach for regression tasks inspired by the FixMatch framework. The feasibility of the proposed solution was preliminarily evaluated through an in-silico study using synthetic data and Monte Carlo simulation. Experimental results for organ dose prediction yielded promising outcomes, showing that the use of pseudo-labeled data provides better accuracy compared to using only labeled data.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 13 figures, 5 tables</p></details> |

